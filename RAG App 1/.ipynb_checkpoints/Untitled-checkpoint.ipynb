{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3855f4f-3112-423f-86db-8d10c1a5b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a711e62-6f9d-4265-81fa-13c54faed88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd83372-398e-4d49-afa7-66b1b2651aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU \"langchain[google-genai]\" --use-deprecated=legacy-resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bc73d-3cfe-4185-b6da-a9a9aad478a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce881a-60cd-4167-980a-6dd6fceffc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-chroma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419a5b5-552f-4d29-b57a-26c3cdf6e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%skip\n",
    "#I had some problems running this on my mac. Make sure you use this if you need to\n",
    "%pip uninstall -y protobuf\n",
    "%pip install protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d9f0c-6aee-4c32-a576-0cc1d5540726",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd636d37-307a-4e16-b696-f1576226e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install urllib3==1.26.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdc514-c37c-4497-b44a-ce2cc8a41828",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain_community pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d416ae-c1e5-4539-899c-226b2bdf5728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAY\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#Here we just load in all the API keys and choose what AI model we want to run. \n",
    "#We setup the vector store and embeddings to later store our indices into to retrieve later.\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter Langsmith API Key\")\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "print(\"YAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c0cab8-7022-4487-9d68-8b48ff75b331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dnutg\\00007256-200333070-00004.pdf now...\n",
      "Loading the dnutg\\0003-4819-118-6-199303150-00008.pdf now...\n",
      "Loading the dnutg\\paper1.pdf now...\n",
      "Finished loading 43 documents\n"
     ]
    }
   ],
   "source": [
    "#Load papers \n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "directory = \"dnutg\"\n",
    "all_docs = []\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        print(f\"Loading the {file_path} now...\")\n",
    "        loader = PyMuPDFLoader(file_path, mode=\"page\", extract_tables=\"markdown\",)\n",
    "\n",
    "        try:\n",
    "            current_doc = loader.load()\n",
    "            all_docs.extend(current_doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in loading the file\")\n",
    "print(f\"Finished loading {len(all_docs)} documents\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101bbd6a-0899-49be-be38-7b9a73613778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split dem cheeks boi (into a diclosed number of subdocs): 278 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, #chunk size\n",
    "    chunk_overlap=200, #chunk overlap\n",
    "    add_start_index=True, #track index\n",
    ")\n",
    "all_splits = text_splitter.split_documents(all_docs)\n",
    "print(f\"Split dem cheeks boi (into a diclosed number of subdocs): {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae9567e-23d9-4853-8670-22fd1e60d578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f2776a46-6e49-49a7-828a-3aa44d28e123', '3c032c25-732b-4cfd-a791-f0b4d5a2ab87', '277659ba-ffca-48be-a1c0-8c4e12041b3d']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b04b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"You are a highly knowledgeable AI assistant specializing in cardiovascular health and medical research.\n",
    "Your primary goal is to provide accurate, evidence-based answers to user questions about heart rate, heart health, and related medical conditions.\n",
    "\n",
    "Answer the question ONLY based on the following context. If the answer cannot be found in the context, please respond to the best of your given ability with the context. You don't have to answer the question if you cannot, but try to give as much context to answering the question as possible. Do not make up information.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "sample_context = \"\"\"\n",
    "A study on resting heart rate found that a rate between 60-100 is normal.\n",
    "\"\"\"\n",
    "\n",
    "sample_question = \"What is a good heart rate?\"\n",
    "\n",
    "prompt_value = prompt.invoke({\"context\":sample_context, \"question\":sample_question})\n",
    "\n",
    "example_messages = prompt_value.to_messages()\n",
    "assert len(example_messages) == 1\n",
    "#print(example_messages[0].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79ef5b-1f17-4b44-a244-ba68e0e9637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query analysis: optimize user prompts to make sense to llm\n",
    "total_docs = len(all_splits)\n",
    "third = total_docs // 3\n",
    "for i, doc in enumerate(all_splits):\n",
    "    if i<third:\n",
    "        doc.metadata[\"section\"] = \"begin\"\n",
    "    elif i<2*third:\n",
    "        doc.metadata[\"section\"] = \"mid\"\n",
    "    else:\n",
    "        doc.metadata[\"section\"] = \"end\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4b4d5b2-1329-4962-b6f2-8ab85194341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update docs in the vector store\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c3400a-fd95-4ad0-9b66-ba8a2eee1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model for state of HumMsg -> AIMsg -> ToolMsg -> AIMsg\n",
    "#Also augments queries w tools\n",
    "from langgraph.graph import MessagesState, StateGraph, END\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eb12322-c30b-4425-aba5-6b43f28fcca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "#gen AI message that could include tool-call\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Gen tool call for retrieval or prep for llm to respond\"\"\"\n",
    "    llm_wtool = llm.bind_tools([retrieve])\n",
    "    response = llm_wtool.invoke(state[\"messages\"])\n",
    "    \"\"\"MessagesState appends messages to state instead of overwrite\"\"\"\n",
    "    return {\"messages\":[response]}\n",
    "\n",
    "#then execute retrieval\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "#gen response w retrieved content\n",
    "def generate(state: MessagesState):\n",
    "    #get tool msgs\n",
    "    recent_tmsgs = []\n",
    "    for message in reversed(state['messages']):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tmsgs.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tmsgs = recent_tmsgs[::-1]\n",
    "\n",
    "    #format into prompt\n",
    "    docs_words = \"\\n\\n\".join(doc.content for doc in tmsgs)\n",
    "    system_msg = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_words}\"\n",
    "    )\n",
    "    convo = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_msg)] + convo\n",
    "\n",
    "    #run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fad6b8-5425-44e5-8635-7621fc2ec5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#define schema for search query using structured output\n",
    "from typing import Literal\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search Query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"begin\", \"mid\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\"\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b922d7-59ab-402c-8e70-d1bced06ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#We use langGraph to tie together retrievel and generation into simpler process\n",
    "#Makes it easier to update later + easy to trace steps of the application\n",
    "from langgraph.graph import START, StateGraph, MessagesState\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter = lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "#now make graph object that compiles all components into one\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d77144a-6c09-4ad2-8c05-c13626ba6427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#workflow display\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6547bfb-37a6-4c59-bad0-f463a545e486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is heart rate variability?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (3ad6e82c-fcf7-4a88-9f5a-264c60cb18bc)\n",
      " Call ID: 3ad6e82c-fcf7-4a88-9f5a-264c60cb18bc\n",
      "  Args:\n",
      "    query: heart rate variability\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'producer': 'Acrobat Distiller 7.0.5 pour Macintosh', 'creator': 'Elsevier', 'creationdate': '2016-07-18T16:22:02+05:30', 'source': 'dnutg\\\\paper1.pdf', 'file_path': 'dnutg\\\\paper1.pdf', 'total_pages': 8, 'format': 'PDF 1.7', 'title': 'Determinants of heart rate variability', 'author': 'Hisako Tsuji', 'subject': 'Journal of the American College of Cardiology, (1996) 1539-1546. doi:10.1016/S0735-1097(96)00342-7', 'keywords': '', 'moddate': '2016-07-18T16:22:02+05:30', 'trapped': '', 'modDate': \"D:20160718162202+05'30'\", 'creationDate': \"D:20160718162202+05'30'\", 'page': 3, 'start_index': 0}\n",
      "Content: . . \n",
      "N\n",
      "\n",
      "Source: {'producer': 'OpenPDF 1.3.30', 'creator': '', 'creationdate': '2025-06-24T04:04:05+02:00', 'source': 'dnutg\\\\0003-4819-118-6-199303150-00008.pdf', 'file_path': 'dnutg\\\\0003-4819-118-6-199303150-00008.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-24T04:04:05+02:00', 'trapped': '', 'modDate': \"D:20250624040405+02'00'\", 'creationDate': \"D:20250624040405+02'00'\", 'page': 3, 'start_index': 4824}\n",
      "Content: between ages 5 and 10 years (28). The influence of \n",
      "provocation on heart rate variability (that is, standing \n",
      "438 \n",
      "15 March 1993 • Annals of Internal Medicine • Volume 118 • Number 6 \n",
      "Downloaded from https://annals.org by University of Groningen on 08/16/2023.\n"
     ]
    },
    {
     "ename": "InvalidUpdateError",
     "evalue": "Expected dict, got {'messages: [response]'}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidUpdateError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m input_message = \u001b[33m\"\u001b[39m\u001b[33mWhat is heart rate variability?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_message\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2533\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2531\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2532\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2533\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2534\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2543\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:625\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m    624\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\write.py:86\u001b[39m, in \u001b[36mChannelWrite._write\u001b[39m\u001b[34m(self, input, config)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any, config: RunnableConfig) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     writes = [\n\u001b[32m     79\u001b[39m         ChannelWriteEntry(write.channel, \u001b[38;5;28minput\u001b[39m, write.skip_none, write.mapper)\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry) \u001b[38;5;129;01mand\u001b[39;00m write.value \u001b[38;5;129;01mis\u001b[39;00m PASSTHROUGH\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.writes\n\u001b[32m     85\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\write.py:128\u001b[39m, in \u001b[36mChannelWrite.do_write\u001b[39m\u001b[34m(config, writes, allow_passthrough)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# if we want to persist writes found before hitting a ParentCommand\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# can move this to a finally block\u001b[39;00m\n\u001b[32m    127\u001b[39m write: TYPE_SEND = config[CONF][CONFIG_KEY_SEND]\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m write(\u001b[43m_assemble_writes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\write.py:183\u001b[39m, in \u001b[36m_assemble_writes\u001b[39m\u001b[34m(writes)\u001b[39m\n\u001b[32m    181\u001b[39m     tuples.append((TASKS, w))\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteTupleEntry):\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ww := \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    184\u001b[39m         tuples.extend(ww)\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteEntry):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\graph\\state.py:975\u001b[39m, in \u001b[36mCompiledStateGraph.attach_node.<locals>._get_updates\u001b[39m\u001b[34m(input)\u001b[39m\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    971\u001b[39m     msg = create_error_message(\n\u001b[32m    972\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected dict, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    973\u001b[39m         error_code=ErrorCode.INVALID_GRAPH_NODE_RETURN_VALUE,\n\u001b[32m    974\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m975\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n",
      "\u001b[31mInvalidUpdateError\u001b[39m: Expected dict, got {'messages: [response]'}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
      "During task with name 'generate' and id '4107f705-c3d7-6149-bd7a-956d7be7bbcf'"
     ]
    }
   ],
   "source": [
    "input_message = \"What is heart rate variability?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf6fe5-2596-4ccb-b82c-07c75e2ffc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test app\n",
    "result = graph.invoke({\"question\": \"My heart rate usually rests between 60 to 90. Am I in danger of anything?\"})\n",
    "#print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a74c0f-18d2-4a09-a8a7-e382c44f0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#testing the app using diff method. This one is streaming\n",
    "for step in graph.stream(\n",
    "    {\"question\": \"What is a heart?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8405094-97f2-4a6e-83f0-43e01823d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#Uses stream tokens?? idk \n",
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is a heart rate variability?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
