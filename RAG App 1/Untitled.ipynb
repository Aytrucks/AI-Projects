{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3855f4f-3112-423f-86db-8d10c1a5b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a711e62-6f9d-4265-81fa-13c54faed88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd83372-398e-4d49-afa7-66b1b2651aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU \"langchain[google-genai]\" --use-deprecated=legacy-resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bc73d-3cfe-4185-b6da-a9a9aad478a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce881a-60cd-4167-980a-6dd6fceffc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-chroma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419a5b5-552f-4d29-b57a-26c3cdf6e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%skip\n",
    "#I had some problems running this on my mac. Make sure you use this if you need to\n",
    "%pip uninstall -y protobuf\n",
    "%pip install protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d9f0c-6aee-4c32-a576-0cc1d5540726",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd636d37-307a-4e16-b696-f1576226e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install urllib3==1.26.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdc514-c37c-4497-b44a-ce2cc8a41828",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain_community pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d416ae-c1e5-4539-899c-226b2bdf5728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAY\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#Here we just load in all the API keys and choose what AI model we want to run. \n",
    "#We setup the vector store and embeddings to later store our indices into to retrieve later.\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter Langsmith API Key\")\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "print(\"YAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c0cab8-7022-4487-9d68-8b48ff75b331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dnutg\\00007256-200333070-00004.pdf now...\n",
      "Loading the dnutg\\0003-4819-118-6-199303150-00008.pdf now...\n",
      "Loading the dnutg\\paper1.pdf now...\n",
      "Finished loading 43 documents\n"
     ]
    }
   ],
   "source": [
    "#Load papers \n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "directory = \"dnutg\"\n",
    "all_docs = []\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        print(f\"Loading the {file_path} now...\")\n",
    "        loader = PyMuPDFLoader(file_path, mode=\"page\", extract_tables=\"markdown\",)\n",
    "\n",
    "        try:\n",
    "            current_doc = loader.load()\n",
    "            all_docs.extend(current_doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in loading the file\")\n",
    "print(f\"Finished loading {len(all_docs)} documents\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101bbd6a-0899-49be-be38-7b9a73613778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split dem cheeks boi (into a diclosed number of subdocs): 278 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, #chunk size\n",
    "    chunk_overlap=200, #chunk overlap\n",
    "    add_start_index=True, #track index\n",
    ")\n",
    "all_splits = text_splitter.split_documents(all_docs)\n",
    "print(f\"Split dem cheeks boi (into a diclosed number of subdocs): {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae9567e-23d9-4853-8670-22fd1e60d578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e7129c25-9548-4b3b-bfb4-ae2301b669b5', '389a9b16-a0c5-490d-8f3d-65afd1cd26cf', '2a329cec-0222-489b-9938-bb757f72d950']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b04b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"You are a highly knowledgeable AI assistant specializing in cardiovascular health and medical research.\n",
    "Your primary goal is to provide accurate, evidence-based answers to user questions about heart rate, heart health, and related medical conditions.\n",
    "\n",
    "Answer the question ONLY based on the following context. If the answer cannot be found in the context, please respond to the best of your given ability with the context. You don't have to answer the question if you cannot, but try to give as much context to answering the question as possible. Do not make up information.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "sample_context = \"\"\"\n",
    "A study on resting heart rate found that a rate between 60-100 is normal.\n",
    "\"\"\"\n",
    "\n",
    "sample_question = \"What is a good heart rate?\"\n",
    "\n",
    "prompt_value = prompt.invoke({\"context\":sample_context, \"question\":sample_question})\n",
    "\n",
    "example_messages = prompt_value.to_messages()\n",
    "assert len(example_messages) == 1\n",
    "#print(example_messages[0].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae79ef5b-1f17-4b44-a244-ba68e0e9637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#Query analysis: optimize user prompts to make sense to llm\n",
    "total_docs = len(all_splits)\n",
    "third = total_docs // 3\n",
    "for i, doc in enumerate(all_splits):\n",
    "    if i<third:\n",
    "        doc.metadata[\"section\"] = \"begin\"\n",
    "    elif i<2*third:\n",
    "        doc.metadata[\"section\"] = \"mid\"\n",
    "    else:\n",
    "        doc.metadata[\"section\"] = \"end\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b4d5b2-1329-4962-b6f2-8ab85194341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update docs in the vector store\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c3400a-fd95-4ad0-9b66-ba8a2eee1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model for state of HumMsg -> AIMsg -> ToolMsg -> AIMsg\n",
    "#Also augments queries w tools\n",
    "from langgraph.graph import MessagesState, StateGraph, END\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eb12322-c30b-4425-aba5-6b43f28fcca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition, create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "#gen AI message that could include tool-call\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Gen tool call for retrieval or prep for llm to respond\"\"\"\n",
    "    llm_wtool = llm.bind_tools([retrieve])\n",
    "    response = llm_wtool.invoke(state[\"messages\"])\n",
    "    \"\"\"MessagesState appends messages to state instead of overwrite\"\"\"\n",
    "    return {\"messages\":[response]}\n",
    "\n",
    "#then execute retrieval\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "#gen response w retrieved content\n",
    "def generate(state: MessagesState):\n",
    "    #get tool msgs\n",
    "    recent_tmsgs = []\n",
    "    for message in reversed(state['messages']):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tmsgs.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tmsgs = recent_tmsgs[::-1]\n",
    "\n",
    "    #format into prompt\n",
    "    docs_words = \"\\n\\n\".join(doc.content for doc in tmsgs)\n",
    "    system_msg = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_words}\"\n",
    "    )\n",
    "    convo = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_msg)] + convo\n",
    "\n",
    "    #run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "agent = create_react_agent(llm, [retrieve], checkpointer=memory)\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "#put an ID to the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc101\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8fad6b8-5425-44e5-8635-7621fc2ec5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#define schema for search query using structured output\n",
    "from typing import Literal\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search Query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"begin\", \"mid\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\"\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5b922d7-59ab-402c-8e70-d1bced06ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#We use langGraph to tie together retrievel and generation into simpler process\n",
    "#Makes it easier to update later + easy to trace steps of the application\n",
    "from langgraph.graph import START, StateGraph, MessagesState\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter = lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "#now make graph object that compiles all components into one\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d77144a-6c09-4ad2-8c05-c13626ba6427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#workflow display\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91e240a1-21dc-4f2d-811e-317d0d99a6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How can I use this learning in my own life?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (a6817b85-a050-470f-a185-2209be28c32a)\n",
      " Call ID: a6817b85-a050-470f-a185-2209be28c32a\n",
      "  Args:\n",
      "    query: how can heart rate variability be used in daily life\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'producer': 'Acrobat Distiller 7.0.5 pour Macintosh', 'creator': 'Elsevier', 'creationdate': '2016-07-18T16:22:02+05:30', 'source': 'dnutg\\\\paper1.pdf', 'file_path': 'dnutg\\\\paper1.pdf', 'total_pages': 8, 'format': 'PDF 1.7', 'title': 'Determinants of heart rate variability', 'author': 'Hisako Tsuji', 'subject': 'Journal of the American College of Cardiology, (1996) 1539-1546. doi:10.1016/S0735-1097(96)00342-7', 'keywords': '', 'moddate': '2016-07-18T16:22:02+05:30', 'trapped': '', 'modDate': \"D:20160718162202+05'30'\", 'creationDate': \"D:20160718162202+05'30'\", 'page': 2, 'start_index': 2372}\n",
      "Content: or removed as a group. Whereas it is common to define \n",
      "statistical significance with a Type I error rate of alpha 0.05, we \n",
      "adopted a more stringent alpha 0.001 for testing multiple \n",
      "variables across three outcomes; furthermore, we dtfined an \n",
      "“important” variable as onk that contributed a.‘partial R’ \n",
      "statistic ZO.005. \n",
      "Normative values of heart rate variability were generated \n",
      "from a subset of subjects who were free of coronary heart \n",
      "disease, cerebrovascular disease, congestive heart failure and \n",
      "diabetes mellitus and who were not receiving cardioactive \n",
      "medications. We further restricted this reference sample to \n",
      "subjects 20 to 79 years old with heart rates between 40 and \n",
      "99 beatslmin. Linear regression was used with the log- \n",
      "transformed data to account for age and heart rate. Estimates \n",
      "were made of the 5th. 25th and 50th percentile values by \n",
      "applying normal theory to the natural log-transformed data \n",
      "before transforming back to the origin;;1 units. \n",
      "Results\n",
      "\n",
      "Source: {'producer': 'OpenPDF 1.3.30', 'creator': '', 'creationdate': '2025-06-24T04:04:05+02:00', 'source': 'dnutg\\\\0003-4819-118-6-199303150-00008.pdf', 'file_path': 'dnutg\\\\0003-4819-118-6-199303150-00008.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-24T04:04:05+02:00', 'trapped': '', 'modDate': \"D:20250624040405+02'00'\", 'creationDate': \"D:20250624040405+02'00'\", 'page': 2, 'start_index': 830}\n",
      "Content: can be influenced by thermal skin stimulation (15) and \n",
      "are thought to arise from thermoregulatory peripheral \n",
      "blood flow adjustments. The fluctuations in peripheral \n",
      "vascular resistance are accompanied by \n",
      "fluctuations \n",
      "with the same frequency in blood pressure and heart \n",
      "rate (15) and are mediated by the sympathetic nervous \n",
      "system. \n",
      "Heart Rate Variability Measurement \n",
      "Heart rate variability can be assessed in two ways: by \n",
      "calculation of indices (16) based on statistical operations \n",
      "on R-R intervals (time domain analysis) or by spectral \n",
      "(frequency domain) analysis of an array of R-R intervals \n",
      "(4). Both methods require accurate timing of R waves. \n",
      "The analysis can be performed on short electrocardio-\n",
      "gram (ECG) segments (lasting from 0.5 to 5 minutes) or \n",
      "on 24-hour ECG recordings. \n",
      "Time Domain Analysis \n",
      "Two types of heart rate variability indices are distin-\n",
      "guished in time domain analysis (Figure 2, top). Beat-\n",
      "to-beat or short-term variability (STV) indices represent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Understanding heart rate variability can be useful for improving your overall health and well-being. Here are a few ways you can apply this knowledge in your own life:\n",
      "\n",
      "*   **Lifestyle adjustments:** Knowing that lifestyle factors influence HRV, you can focus on making healthier choices. This includes regular exercise, a balanced diet, sufficient sleep, and stress management techniques like meditation or yoga. Monitoring your HRV can give you insights into how these changes affect your body's adaptability.\n",
      "*   **Personalized training:** Athletes can use HRV to optimize their training schedules. Monitoring HRV can help determine when to push harder and when to prioritize rest and recovery, preventing overtraining and improving performance.\n",
      "*   **Stress management:** If you find that your HRV decreases during stressful periods, you can actively implement stress-reduction techniques to improve your body's resilience.\n",
      "*   **Health monitoring:** While not a substitute for medical advice, tracking your HRV can provide valuable insights into your overall health. If you notice consistent decreases in HRV, it might be a signal to consult with a healthcare professional to rule out any underlying issues.\n",
      "*   **Biofeedback:** HRV biofeedback is a technique that uses real-time HRV data to help you learn to consciously regulate your heart rate and improve your body's ability to manage stress.\n",
      "\n",
      "Keep in mind that HRV is just one piece of the puzzle when it comes to your health. It's best to consult with a healthcare professional for personalized advice and guidance.\n"
     ]
    }
   ],
   "source": [
    "input_message = (\n",
    "    \"How can I use this learning in my own life?\"\n",
    "    \n",
    ")\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52cf6fe5-2596-4ccb-b82c-07c75e2ffc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#test app\n",
    "result = graph.invoke({\"question\": \"My heart rate usually rests between 60 to 90. Am I in danger of anything?\"})\n",
    "#print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8a74c0f-18d2-4a09-a8a7-e382c44f0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#testing the app using diff method. This one is streaming\n",
    "for step in graph.stream(\n",
    "    {\"question\": \"What is a heart?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8405094-97f2-4a6e-83f0-43e01823d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#Uses stream tokens?? idk \n",
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is a heart rate variability?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
